{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db9b0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa436d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "full_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a2f0d172-2d3c-49be-8969-4212c9025c9b",
       "rows": [
        [
         "0",
         "real",
         "Foreign Democrat final. more tax development both store agreement lawyer hear outside continue reach difference yeah figure your power fear identify there protect security great national nothing fast story why late nearly bit cost tough since question to power almost future young conference behind ahead building teach million box receive Mrs risk benefit month compare environment class imagine you vote community reason set once idea him answer many how purpose deep training game own true language garden of partner result face military discover discover data glass bed maintain test way development across top culture glass yes decision hope necessary as trade organization talk debate peace stay community development six wide write itself several fight teach billion for common fear we personal church establish store kind hundred debate hotel cut sister audience sound case that stay within information trouble be debate great themselves responsibility force people hundred bar miss others sometimes build room interesting however charge what especially north no especially us travel industry about including face ten behind black series place age soldier early trouble middle would along case what money significant sound song reason poor free want thank cultural range shoulder rest movie political fear hear past leader up edge professor determine law act change middle prove say notice travel open director argue economic seven game matter season"
        ],
        [
         "1",
         "fake",
         "To offer down resource great point. probably guess western behind likely next investment consumer range wrong exactly once attack shoulder movie partner daughter on executive tonight factor push development pass question field firm accept I represent answer computer win fast small character total myself air must difficult green fast writer adult though individual learn interview our available drug against group produce before large wish find even media nature then last computer project story special stand lead build during ball contain road since history customer garden figure kind throw tell discuss remain view morning put mouth while serve great certain free two structure skin yard position suffer fast someone ok mind must something outside position write theory ok letter for debate seat top fall authority bit deep there get man view loss bring friend free certain economic final occur summer similar best discover area real area still scientist social everybody front direction arrive open own down next lawyer baby already size stand put financial sister clear whether save into realize right break quickly music customer price prevent truth effort which probably strong friend everything also body together political interview least research benefit why dog mean near interest unit seek blood leader husband bring teacher age apply fill guess store south woman television worry build young style maybe agreement ability relate amount actually quite whose smile student current mother simply gun store Republican none when shoulder market admit knowledge animal majority product attorney approach on probably"
        ],
        [
         "2",
         "fake",
         "Himself church myself carry. them identify forward present success risk several front pull blood choose born prove we clear approach language election future plant other those yourself all thing side soon guy vote him should practice dream until find despite less artist minute although teacher social eye top less make back care thus much small act outside college because up travel continue night name military room himself instead many month follow long president community people like attention fall crime history despite fill recently need commercial investment address send religious join opportunity story but idea exactly back difference loss degree whose throughout lead response almost toward themselves card national structure state arm low threat property eat bill public trip bed note hair teach defense citizen my rather believe say level wall short religious theory hair respond town return discussion investment never success entire admit develop south ability television yard daughter while fire modern send suggest skin could outside work office protect determine teach structure door fund ready gun role everyone often father establish majority point set choice meet think treatment animal audience guess hear student other certain inside assume check approach senior body once condition just trial occur foot explain police certain kid into special share deal write southern nature exactly respond kid help cause manager TV ago word nor her care reality daughter find answer affect"
        ],
        [
         "3",
         "fake",
         "You unit its should. phone which item yard Republican safe where police identify either once participant not man human tough enough offer high imagine point police woman paper cover many reach service will likely president conference film agree discover moment positive help task share necessary story right finally compare traditional change for reason purpose single crime available point building wear speech about summer why senior couple somebody PM remember push less data hotel authority situation for much visit general society firm positive player play page miss brother window indeed energy lose stage perhaps itself range common story hot strong adult produce next carry guess television travel form meeting industry shoulder market sure certain parent walk husband behind cultural whatever collection difficult we team probably produce quickly health full white laugh represent religious line force I exist admit statement try by front short pattern baby open claim these chance face else way decade sing nature rich white bring employee catch time industry official family million camera some including everybody security wait art vote maybe rich detail sort another let forget product police third evidence end old throughout student discussion office put nature whatever figure sign nature population town team against arm war include need visit would wait small just bed I line school eight might bag official worker television condition so institution information full protect food fight attack include current even per chair accept reflect speak answer bag officer understand good weight money movement main traditional western information account adult even gas"
        ],
        [
         "4",
         "fake",
         "Billion believe employee summer how. wonder myself fact difficult course forget exactly pattern both sell training understand so ahead single western ago worry direction various agree first remember tonight year building agreement involve effect over even total game look need evidence particularly attorney agency apply produce theory deep ok fund relationship suffer guess put build morning quickly home authority physical choice can environment skin fill cost state force fire again establish recent two world style beyond bad while game memory world what hair anyone simply week try sport animal yeah hundred visit note within value various military laugh politics official between front would upon attack shoulder administration wish space receive less thing with structure produce cultural approach law doctor money interesting lawyer TV each activity however child item space sell movie south make around number camera past process fear wait total city site next party charge father up knowledge compare front attack check watch beat yard knowledge before quality field institution month child actually right become collection camera need include pattern after behind best ability expect possible star girl four radio establish charge budget suggest thousand she base become blood direction middle support fight game foot court reduce single whether or at score anything its sister management at focus machine single husband through free language run want shake goal food"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>Foreign Democrat final. more tax development b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>To offer down resource great point. probably g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>Himself church myself carry. them identify for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>You unit its should. phone which item yard Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>Billion believe employee summer how. wonder my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          full_text\n",
       "0  real  Foreign Democrat final. more tax development b...\n",
       "1  fake  To offer down resource great point. probably g...\n",
       "2  fake  Himself church myself carry. them identify for...\n",
       "3  fake  You unit its should. phone which item yard Rep...\n",
       "4  fake  Billion believe employee summer how. wonder my..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../Data/fake_news_dataset.csv\")\n",
    "\n",
    "df[\"full_text\"] = df[\"title\"].fillna('') + \" \" + df[\"text\"].fillna('')\n",
    "\n",
    "df[[\"label\", \"full_text\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fba2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
    "df[\"label\"] = df[\"label\"].map({\"fake\": 0, \"real\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9101d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f5b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(word) \n",
    "        for word in tokens if word not in stop_words\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "documents = df[\"full_text\"].apply(clean_text).tolist()\n",
    "df[\"cleaned_text\"] = documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581ff4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5aeddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_all = CountVectorizer(max_features=5000)\n",
    "X_all = vectorizer_all.fit_transform(documents)\n",
    "vocab = vectorizer_all.get_feature_names_out()\n",
    "X_array = X_all.toarray()\n",
    "labels = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0afa215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "real_indices = [i for i, label in enumerate(labels) if label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816937fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mean = np.mean(X_array[fake_indices], axis=0)\n",
    "real_mean = np.mean(X_array[real_indices], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8daea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_scores = fake_mean - real_mean\n",
    "df_keywords = pd.DataFrame({\n",
    "    \"word\": vocab,\n",
    "    \"fake_score\": word_scores\n",
    "}).sort_values(by=\"fake_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7e299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.023\n",
    "important_words = df_keywords[df_keywords[\"fake_score\"] > threshold][\"word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6768c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_selected = CountVectorizer(vocabulary=important_words)\n",
    "X_selected = vectorizer_selected.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0f04507",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vec = vectorizer.fit_transform(df[\"cleaned_text\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b594238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      " Accuracy: 0.5012\n",
      " F1 Score: 0.4928\n",
      "----------------------------------------\n",
      "Naive Bayes\n",
      " Accuracy: 0.5100\n",
      " F1 Score: 0.4528\n",
      "----------------------------------------\n",
      "SVM (Linear)\n",
      " Accuracy: 0.5005\n",
      " F1 Score: 0.4921\n",
      "----------------------------------------\n",
      "Random Forest\n",
      " Accuracy: 0.5002\n",
      " F1 Score: 0.4752\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"SVM (Linear)\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{name}\\n Accuracy: {acc:.4f}\\n F1 Score: {f1:.4f}\\n\" + \"-\"*40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
